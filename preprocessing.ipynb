{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eee62ff",
   "metadata": {},
   "source": [
    "# Biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dee1d4",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e12d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "csv_file = \"song_data.csv\"\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f8cc11",
   "metadata": {},
   "source": [
    "# Opis danych\n",
    "\n",
    "**song_name** : *object* - nazwa piosenki\n",
    "\n",
    "**song_popularity** : *integer* - Popularność utworu. Wartość będzie mieścić się w przedziale od 0 do 100, przy czym 100 oznacza największą popularność. Popularność jest obliczana za pomocą algorytmu i opiera się głównie na całkowitej liczbie odtworzeń utworu i na tym, jak niedawno te odtworzenia miały miejsce. Ogólnie rzecz biorąc, utwory, które są obecnie często odtwarzane, będą miały wyższą popularność niż utwory, które były często odtwarzane w przeszłości. Zduplikowane utwory (np. ten sam utwór z singla i albumu) są oceniane niezależnie. Popularność artysty i albumu jest wyznaczana matematycznie na podstawie popularności utworu.\n",
    "\n",
    "**song_duration_ms** : *integer* - Czas trwania piosenki w milisekundach.\n",
    "\n",
    "**acousticness** : *float* - Mówi o tym jak dużą mamy pewność, że piosenka jest akustyczna. 1.0 oznacza dużą pewność.\n",
    "\n",
    "**danceability** : *float* - Ocena jak bardzo taneczna jest piosenka, na podstawie kombinacji aspektów muzycznych, takich jak tempo, rytm, beat. 0.0 to najmniejsza taneczność a 1.0 to największa.\n",
    "\n",
    "**energy** : *float* - Mierzy energiczność piosenki w oparciu o dynamikę, głośność, barwę dżwięku, częstotliwość i ogólną entropię.\n",
    "\n",
    "**instrumentalness** : *float* - Przewidywanie czy muzyka nie zawiera wokalu. Im bliżej do 1.0 tym większe prawdopodobieństwo, że piosenka nie zawiera wokalu. Wartości powyżej 0.5 mają reprezentować utwory intrumentalne.\n",
    "\n",
    "**key** : *integer* - Tonacja utworu. 0 to C, 1 to C#/D♭, itd. Jeżeli tonacja jest nie podana przyjmuje wartość -1.\n",
    "\n",
    "**liveness** : *float* - Wykrywa obecność publiczności w nagraniu. Wyższe wartości żywotności reprezentują zwiększone prawdopodobieństwo, że utwór został wykonany na żywo. Wartość powyżej 0,8 stanowi silne prawdopodobieństwo, że utwór jest nagraniem na żywo.\n",
    "\n",
    "**audio_mode** : *binary* - Tryb wskazuje modalność (durową lub molową) utworu, czyli rodzaj skali, z której pochodzi jego treść melodyczna. Durowa jest reprezentowana przez 1, a molowa przez 0.\n",
    "\n",
    "**speechiness** : *float* - Wykrywa obecność mówionych słów w utworze. Im bardziej nagranie przypomina mowę (np. talk-show, audiobook, poezja), tym bliżej wartość atrybutu jest do 1,0. Wartości powyżej 0,66 opisują utwory, które prawdopodobnie składają się całkowicie z mówionych słów. Wartości między 0,33 a 0,66 opisują utwory, które mogą zawierać zarówno muzykę, jak i mowę, zarówno w sekcjach, jak i warstwach, w tym przypadku muzyki rap. Wartości poniżej 0,33 najprawdopodobniej reprezentują muzykę i inne utwory niespokojne.\n",
    "\n",
    "**tempo** : *float* - Ogólnie szacowane tempo utworu wyrażone w uderzeniach na minutę (BPM). Przykład: 118.211 BPM\n",
    "\n",
    "**time_signature** : *integer* - Szacowane metrum utworu. Metrum określa, ile uderzeń zawiera każda takt (czyli każda \"miara\"). Metrum jest wyrażane jako liczba uderzeń w takt, na przykład \"3/4\" lub \"7/4\".\n",
    "\n",
    "**audio_valence** : *float* - Miara od 0.0 do 1.0 opisująca muzyczną pozytywność przekazywaną przez utwór. Utwory z wysoka wartością brzmią bardziej pozytywnie (np. szczęśliwie, radośnie, euforycznie), podczas gdy utwory o niskiej mierze brzmią bardziej negatywnie (np. smutnie, przygnębiono, gniewnie).\n",
    "\n",
    "W przypadku zmiennych **key** oraz **tempo**, konieczne będzie użycie techniki One Hot Encoding, w celu zapisu ich jako zmienne binarne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a1a37b",
   "metadata": {},
   "source": [
    "# Usuwanie duplikatów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(df['song_name'])\n",
    "if len(Counter({k: c for k, c in counter.items() if c > 1})) != 0:\n",
    "  df = df.drop_duplicates(subset='song_name')\n",
    "  df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6900d18",
   "metadata": {},
   "source": [
    "# Statystyki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f10e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e623912",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df[[\"key\",\"audio_mode\", \"time_signature\"]].copy()\n",
    "num = df.drop([\"song_name\",\"key\",\"audio_mode\", \"time_signature\"], axis = 1)\n",
    "Y = df[\"song_popularity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0b8ea",
   "metadata": {},
   "source": [
    "# Wizualizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c42d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical variables\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "ax = fig.gca()\n",
    "num.hist(ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eccd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical values\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15,5))\n",
    "cat[\"key\"].value_counts().plot(kind='bar', ax = ax1)\n",
    "cat[\"time_signature\"].value_counts().plot(kind='bar', ax = ax2)\n",
    "cat[\"audio_mode\"].value_counts().plot(kind='bar', ax = ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e360e0",
   "metadata": {},
   "source": [
    "# Zmienne kategoryczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['time_signature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwamy wiersze gdzie wartość zmiennej time_signature wynosi 0 i 1\n",
    "df.drop(df[ df['time_signature'] == 1 ].index, inplace = True)\n",
    "df.drop(df[ df['time_signature'] == 0 ].index, inplace = True)\n",
    "Counter(df['time_signature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be87064",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['audio_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc396ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf8b6e5",
   "metadata": {},
   "source": [
    "# Korelacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix=num.corr()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "ax = sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r')\n",
    "ax.xaxis.tick_top()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a6ae5d",
   "metadata": {},
   "source": [
    "# Normalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d060770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = num.drop([\"song_popularity\"], axis = 1)\n",
    "X.iloc[:,0:]=scaler.fit_transform(X.iloc[:,0:].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542c491",
   "metadata": {},
   "source": [
    "# PCA (dla numerycznych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d575fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "print('Procent warincji wyjaśniony przez components: {}'.format(pca.explained_variance_ratio_))\n",
    "print('Procent warincji wyjaśniony przez components (suma): {}'.format(pca.explained_variance_ratio_.cumsum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5b911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
