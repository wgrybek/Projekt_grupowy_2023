{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "432412fb",
   "metadata": {},
   "source": [
    "# Biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca86b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366c25a",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148f44a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "csv_file = \"song_data.csv\"\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15e9892",
   "metadata": {},
   "source": [
    "# Opis danych\n",
    "\n",
    "**song_name** : *object* - nazwa piosenki\n",
    "\n",
    "**song_popularity** : *integer* - Popularność utworu. Wartość będzie mieścić się w przedziale od 0 do 100, przy czym 100 oznacza największą popularność. Popularność jest obliczana za pomocą algorytmu i opiera się głównie na całkowitej liczbie odtworzeń utworu i na tym, jak niedawno te odtworzenia miały miejsce. Ogólnie rzecz biorąc, utwory, które są obecnie często odtwarzane, będą miały wyższą popularność niż utwory, które były często odtwarzane w przeszłości. Zduplikowane utwory (np. ten sam utwór z singla i albumu) są oceniane niezależnie. Popularność artysty i albumu jest wyznaczana matematycznie na podstawie popularności utworu.\n",
    "\n",
    "**song_duration_ms** : *integer* - Czas trwania piosenki w milisekundach.\n",
    "\n",
    "**acousticness** : *float* - Mówi o tym jak dużą mamy pewność, że piosenka jest akustyczna. 1.0 oznacza dużą pewność.\n",
    "\n",
    "**danceability** : *float* - Ocena jak bardzo taneczna jest piosenka, na podstawie kombinacji aspektów muzycznych, takich jak tempo, rytm, beat. 0.0 to najmniejsza taneczność a 1.0 to największa.\n",
    "\n",
    "**energy** : *float* - Mierzy energiczność piosenki w oparciu o dynamikę, głośność, barwę dżwięku, częstotliwość i ogólną entropię.\n",
    "\n",
    "**instrumentalness** : *float* - Przewidywanie czy muzyka nie zawiera wokalu. Im bliżej do 1.0 tym większe prawdopodobieństwo, że piosenka nie zawiera wokalu. Wartości powyżej 0.5 mają reprezentować utwory intrumentalne.\n",
    "\n",
    "**key** : *integer* - Tonacja utworu. 0 to C, 1 to C#/D♭, itd. Jeżeli tonacja jest nie podana przyjmuje wartość -1.\n",
    "\n",
    "**liveness** : *float* - Wykrywa obecność publiczności w nagraniu. Wyższe wartości żywotności reprezentują zwiększone prawdopodobieństwo, że utwór został wykonany na żywo. Wartość powyżej 0,8 stanowi silne prawdopodobieństwo, że utwór jest nagraniem na żywo.\n",
    "\n",
    "**audio_mode** : *binary* - Tryb wskazuje modalność (durową lub molową) utworu, czyli rodzaj skali, z której pochodzi jego treść melodyczna. Durowa jest reprezentowana przez 1, a molowa przez 0.\n",
    "\n",
    "**speechiness** : *float* - Wykrywa obecność mówionych słów w utworze. Im bardziej nagranie przypomina mowę (np. talk-show, audiobook, poezja), tym bliżej wartość atrybutu jest do 1,0. Wartości powyżej 0,66 opisują utwory, które prawdopodobnie składają się całkowicie z mówionych słów. Wartości między 0,33 a 0,66 opisują utwory, które mogą zawierać zarówno muzykę, jak i mowę, zarówno w sekcjach, jak i warstwach, w tym przypadku muzyki rap. Wartości poniżej 0,33 najprawdopodobniej reprezentują muzykę i inne utwory niespokojne.\n",
    "\n",
    "**tempo** : *float* - Ogólnie szacowane tempo utworu wyrażone w uderzeniach na minutę (BPM). Przykład: 118.211 BPM\n",
    "\n",
    "**time_signature** : *integer* - Szacowane metrum utworu. Metrum określa, ile uderzeń zawiera każda takt (czyli każda \"miara\"). Metrum jest wyrażane jako liczba uderzeń w takt, na przykład \"3/4\" lub \"7/4\".\n",
    "\n",
    "**audio_valence** : *float* - Miara od 0.0 do 1.0 opisująca muzyczną pozytywność przekazywaną przez utwór. Utwory z wysoka wartością brzmią bardziej pozytywnie (np. szczęśliwie, radośnie, euforycznie), podczas gdy utwory o niskiej mierze brzmią bardziej negatywnie (np. smutnie, przygnębiono, gniewnie).\n",
    "\n",
    "W przypadku zmiennych **key** oraz **tempo**, konieczne będzie użycie techniki One Hot Encoding, w celu zapisu ich jako zmienne binarne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a983127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e7396",
   "metadata": {},
   "source": [
    "# Usuwanie duplikatów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(df['song_name'])\n",
    "if len(Counter({k: c for k, c in counter.items() if c > 1})) != 0:\n",
    "  df = df.drop_duplicates(subset='song_name')\n",
    "  df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51382627",
   "metadata": {},
   "source": [
    "# Statystyki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22fc8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0ab39",
   "metadata": {},
   "source": [
    "# Wizualizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,15))\n",
    "ax = fig.gca()\n",
    "df.hist(ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e65d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06499fcf",
   "metadata": {},
   "source": [
    "# Zmienne kategoryczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314514ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['time_signature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8af072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwamy wiersze gdzie wartość zmiennej time_signature wynosi 0 i 1\n",
    "df.drop(df[ df['time_signature'] == 1 ].index, inplace = True)\n",
    "df.drop(df[ df['time_signature'] == 0 ].index, inplace = True)\n",
    "Counter(df['time_signature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a49162",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['audio_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0852485",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(df['audio_mode'],return_counts=True)\n",
    "ticks = range(len(counts))\n",
    "plt.bar(ticks,counts, align='center', )\n",
    "plt.xticks(ticks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(df['key'],return_counts=True)\n",
    "ticks = range(len(counts))\n",
    "plt.bar(ticks,counts, align='center')\n",
    "plt.xticks(ticks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a624a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(df['time_signature'],return_counts=True)\n",
    "ticks = range(len(counts))\n",
    "plt.bar(ticks,counts, align='center')\n",
    "plt.xticks(ticks, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade61947",
   "metadata": {},
   "source": [
    "# Korelacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1668b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels=['song_popularity', 'song_name'], axis=1)\n",
    "correlation_matrix=X.corr()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "ax = sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r')\n",
    "ax.xaxis.tick_top()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a1117",
   "metadata": {},
   "source": [
    "# Normalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X.iloc[:,0:]=scaler.fit_transform(X.iloc[:,0:].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e3d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd111363",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=13)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "print('Procent warincji wyjaśniony przez components: {}'.format(pca.explained_variance_ratio_))\n",
    "print('Procent warincji wyjaśniony przez components (suma): {}'.format(pca.explained_variance_ratio_.cumsum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b2b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
